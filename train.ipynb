{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerko/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "from dataset import MyDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv('data/power/power-hr-train.tsv', sep='\\t')\n",
    "ids = table['id'].tolist()\n",
    "speakers = table['speaker'].tolist()\n",
    "sexes = table['sex'].tolist()\n",
    "texts = table['text'].tolist()\n",
    "texts_en = table['text_en'].tolist()\n",
    "labels = table['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3565/10741 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(ids, speakers, sexes, texts, texts_en, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5][5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Batch 1/357, Batch loss: 2.660856246948242, Average epoch loss: 2.660856246948242\n",
      "Epoch 1/5, Batch 18/357, Batch loss: 0.5561875700950623, Average epoch loss: 0.8168772227234311\n",
      "Epoch 1/5, Batch 35/357, Batch loss: 0.5369201302528381, Average epoch loss: 0.728986212185451\n",
      "Epoch 1/5, Batch 52/357, Batch loss: 0.6352295279502869, Average epoch loss: 0.6959006912433184\n",
      "Epoch 1/5, Batch 69/357, Batch loss: 0.774587094783783, Average epoch loss: 0.683211545581403\n",
      "Epoch 1/5, Batch 86/357, Batch loss: 0.5417715907096863, Average epoch loss: 0.683633224562157\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer_type=torch.optim.Adam,\n",
    "    dataset_train=train_dataset,\n",
    "    dataset_val=test_dataset,\n",
    "    epochs=5,\n",
    "    batch_size=8,\n",
    "    lr=1e-5,\n",
    "    device=torch.device('cpu'),\n",
    "    gamma=0.85,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hr10350',\n",
       " 'e2a099b5e5a0039fa86613f5924149f7',\n",
       " 'M',\n",
       " 'Hvala poštovani saborski zastupniče na pitanju iako čini mi se da je ovo pitanje primjerenije za ministra Čobankovića, jer ovdje se koliko razumijem ne radi o robi robnih zaliha ili nešto što bi bilo vezano za robne zalihe koje su u nadležnosti Ministarstva gospodarstva, rada i poduzetništva. No međutim, mogu reći da o ovoj informaciji koju ste vi dali ću zajedno sa ministrom Čobankovićem prikupiti sve potrebne informacije i proslijediti prema Vladi i ovdje vama u Sabor. Čini se da tu i posla će biti i ima i za kolegu ministra Mlinarića. Ali evo ovog momenta ne mogu odgovoriti na ovo pitanje. Prikupit ćemo informacije i dati vam napismeno. Hvala.',\n",
       " \"Thank you, honourable parliamentary representative, for the question, although this is more appropriate for Minister Cobankovic, because as far as I understand it, it is not about the goods of the goods or something that would be related to the goods that are in the jurisdiction of the Ministry of Economy, Labour and Entrepreneurship. However, I can say that on this information that you have provided, I will gather together with Minister Cobankovic all the necessary information and forward it to the Government and here to you in the Parliament. It seems that there will be work and there will also be for a colleague of Minister Mlinarić. But here's the moment I can't answer this question. We'll gather information and give it to you in writing. Thank you.\",\n",
       " tensor([  101,  1044, 10175,  2050,  2695,  7103,  3490,  7842, 12821,  5488,\n",
       "         23564,  3367,  6279,  8713,  2063,  6583,  6770,  2319,  9103, 24264,\n",
       "          3683, 25022,  3490,  2771,  7367,  4830, 15333,  1051,  6767,  6770,\n",
       "          2319,  6460, 26927,  2213, 20009, 18595,  6460, 23564,  7163, 20528,\n",
       "          2522,  9299,  9142,  2050,  1010, 15333,  2099,  1051, 16872,  6460,\n",
       "          7367, 12849, 18393,  2080, 10958, 28114,  6460,  2213, 11265, 10958,\n",
       "          4305,  1051,  6487,  2072,  6487,  3490,  2232, 23564,  3669,  3270,\n",
       "          6335,  2072,  9089,  2080,  2358,  2080, 12170, 12170,  4135,  2310,\n",
       "         24147, 23564,  6487,  2638, 23564,  3669,  5369, 12849,  6460, 10514,\n",
       "          1057, 23233, 28060, 15460,  3775,  7163, 14117,  3367,  3567,  2175,\n",
       "         13102, 13390, 12096,  3567,  1010, 10958,  2850,  1045, 17491, 20395,\n",
       "          2102, 26942,  3567,  1012,  2053,  2033, 29671, 21823,  2213,  1010,\n",
       "          9587, 12193, 28667,  2072,  4830,  1051,  1051,  6767,  3501, 12367,\n",
       "          6305, 27821, 12849,  9103, 26261,  6819, 29095, 12731, 23564,  6460,\n",
       "          2094,  3630,  7842,  7163, 15687,  2522,  9299,  9142,  6633, 26927,\n",
       "          5283, 23270,  2072, 17917,  2063,  8962,  2890, 24700,  2063, 12367,\n",
       "          6305, 28418,  2063,  1045,  4013, 14540, 28418,  2098, 25090, 26563,\n",
       "          2050, 19163,  2072,  1045,  1051, 16872,  6460, 12436,  2863,  1057,\n",
       "          7842, 12821,  1012, 25022,  3490,  7367,  4830, 10722,  1045, 13433,\n",
       "         14540,  2050,  8292,  2978,  2072,  1045, 10047,  2050,  1045, 23564,\n",
       "         12849, 23115,  2226,  7163, 20528, 19875,  3981, 14735,  1012,  4862,\n",
       "         23408,  2080,  1051,  6767,  2290,  2617,  2050, 11265,  9587, 12193,\n",
       "          1051,  2094,  3995, 14550, 25090,  6583,  1051,  6767,  6770,  2319,\n",
       "          6460,  1012, 26927,  5283, 23270,  8292,  5302, 12367,  6305, 28418,\n",
       "          2063,  1045, 23755,  2072, 12436,  2213, 18996,  2964, 16515,  1012,\n",
       "          1044, 10175,  2050,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
